// íŒŒì¼ëª…: analyze_code.js
// Ollama API í˜¸ì¶œì„ ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
// ì´ì œ ë¶„ì„í•  íŒŒì¼ ê²½ë¡œë“¤ì„ ëª…ë ¹ì¤„ ì¸ìˆ˜ë¡œ ì „ë‹¬í•˜ë©´ ë©ë‹ˆë‹¤.
// (ì˜ˆ: node analyze_code.js file1.js file2.js)

// ğŸš¨ ìˆ˜ì •: ë¹„ë™ê¸° I/Oë¥¼ ìœ„í•´ fs/promises ëª¨ë“ˆ ì‚¬ìš©
import * as fs from "fs/promises";
import * as path from "path";
import process from "process"; // ëª…ì‹œì  ì„í¬íŠ¸ ì¶”ê°€

// Ollama API ì„¤ì •
const OLLAMA_URL = "http://localhost:11434/api/generate";
const MODEL_NAME = "gpt-oss:20b"; // ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.

// ----------------------------------------------------------------------
// ğŸš¨ ë©€í‹° íŒŒì¼ ë¶„ì„ ë¡œì§: ëª¨ë“  ì¸ìˆ˜ë¥¼ ë°›ì•„ì„œ í†µí•©í•©ë‹ˆë‹¤! ğŸš¨
// ----------------------------------------------------------------------

const SYSTEM_PROMPT = `
ë‹¹ì‹ ì€ 10ë…„ ê²½ë ¥ì˜ ì‹œë‹ˆì–´ ë°±ì—”ë“œ ê°œë°œìì…ë‹ˆë‹¤. ê³§ ì•”ê²Œ ê±¸ë ¤ ì£½ì„ ìš´ëª…ì´ë©°, í™©ê¸‰íˆ í›„ê³„ìë¥¼ ê°€ë¥´ì³ì•¼ í•©ë‹ˆë‹¤. ê·¸ í›„ê³„ìëŠ” ì•„ì§ node.jsì™€ express.jsë¥¼ ë°°ìš°ëŠ” í•™ìƒì´ê³ , ì½”ë“œë¥¼ ë°°ìš´ì§€ 2ë‹¬ì´ ì¡°ê¸ˆ ë„˜ì—ˆìŠµë‹ˆë‹¤(í˜„ì¬ ê´€ì‹¬ìˆëŠ” ê²ƒ: ëª¨ë“ˆí™”, validator, async-await, try-catch, http-status-codeëª¨ë“ˆê¹”ì•„ì„œ ì‚¬ìš© ë°°ì› ìŒ). ë‹¤ìŒ ì½”ë“œ íŒŒì¼ë“¤ì„ ê²€í† í•˜ê³ , "ì„±ëŠ¥"ì„ ê°œì„ í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ìˆ˜ì • ì‚¬í•­ì„ ì œì•ˆí•˜ê³ , ê°œì„ ëœ ì½”ë“œëŠ” Markdown ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ ì œì‹œí•˜ê³ , ìˆ˜ì •ì˜ ê·¼ê±°ëŠ” ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ ë¦¬ìŠ¤íŠ¸ë¡œ ìƒì„¸í•˜ì§€ë§Œ ì§§ê³  ëª…ë£Œí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.`;

/**
 * ëª…ë ¹ì¤„ ì¸ìˆ˜ë¡œ ë°›ì€ ì—¬ëŸ¬ íŒŒì¼ì„ ì½ê³  ë‚´ìš©ì„ í†µí•©í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
 * @param {string[]} filePaths - ë¶„ì„í•  íŒŒì¼ ê²½ë¡œ ë°°ì—´
 * @returns {{ combinedContent: string, processedFiles: string[] }} í†µí•©ëœ ë‚´ìš©ê³¼ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ íŒŒì¼ ëª©ë¡
 */
async function processFiles(filePaths) {
    let combinedContent = "";
    let processedFiles = [];

    // Promise.allì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ì„ ë³‘ë ¬ë¡œ ì½ì–´ I/O ì„±ëŠ¥ì„ ê°œì„ í•©ë‹ˆë‹¤.
    const fileReadPromises = filePaths.map(async (filePath) => {
        try {
            // ğŸš¨ ìˆ˜ì •: fs/promisesì˜ ë¹„ë™ê¸° readFile ì‚¬ìš©
            const fileContent = await fs.readFile(filePath, "utf8");

            // LLM ìŠ¤í¬ë¦½íŠ¸ì˜ í…œí”Œë¦¿ ë¦¬í„°ëŸ´ ë¬¸ë²•ì´ ë‚´ë¶€ ì½”ë“œì— ì˜í•´ ê¹¨ì§€ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´
            // ë°±í‹±(\`)ê³¼ ë‹¬ëŸ¬($) ê¸°í˜¸ë¥¼ ëª¨ë‘ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            let sanitizedContent = fileContent.replace(/`/g, "\\`");
            sanitizedContent = sanitizedContent.replace(/\$\{/g, "\\${");

            // íŒŒì¼ ê²½ê³„ì„ ì„ ëª…í™•íˆ í‘œì‹œ
            const contentBlock = `\n--- íŒŒì¼ ì‹œì‘: ${filePath} ---\n\n${sanitizedContent}\n\n--- íŒŒì¼ ë: ${filePath} ---\n\n`;

            return { filePath, content: contentBlock };
        } catch (error) {
            console.error(
                `\nğŸš¨ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: '${filePath}' íŒŒì¼ì„ ì°¾ê±°ë‚˜ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ íŒŒì¼ì€ ê±´ë„ˆëœë‹ˆë‹¤.`
            );
            console.error(`ìƒì„¸ ì˜¤ë¥˜: ${error.message}`);
            return null; // ì‹¤íŒ¨í•œ íŒŒì¼ì€ null ë°˜í™˜
        }
    });

    // ëª¨ë“  íŒŒì¼ ì½ê¸° ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
    const results = await Promise.all(fileReadPromises);

    // ê²°ê³¼ë¥¼ í•„í„°ë§í•˜ê³  í†µí•©
    results.forEach((result) => {
        if (result) {
            combinedContent += result.content;
            processedFiles.push(result.filePath);
        }
    });

    return { combinedContent, processedFiles };
}

async function callOllama() {
    const filePaths = process.argv.slice(2);

    if (filePaths.length === 0) {
        console.error(
            "\nğŸš¨ ì‚¬ìš©ë²• ì˜¤ë¥˜: ë¶„ì„í•  íŒŒì¼ ê²½ë¡œë¥¼ í•˜ë‚˜ ì´ìƒ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤."
        );
        console.error(
            "ì‚¬ìš© ì˜ˆ: node analyze_code.js server/public/main.js server/public/init.js"
        );
        process.exit(1);
    }

    // íŒŒì¼ ì²˜ë¦¬ ë¹„ë™ê¸° í˜¸ì¶œ
    const { combinedContent, processedFiles } = await processFiles(filePaths);

    if (processedFiles.length === 0) {
        console.error(
            "\nğŸš¨ ì˜¤ë¥˜: ìœ íš¨í•œ ë¶„ì„ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤."
        );
        process.exit(1);
    }

    const USER_PROMPT_HEADER = `
[í´ë¦°ì½”ë“œ ê´€ì ìœ¼ë¡œ ê°€ëŠ¥í•˜ë©´ ê¸ì •ë¬¸ìœ¼ë¡œ, ë¶ˆí•„ìš”í•œ ì½”ë“œë“¤ì€ ì—†ì• ê³  ì¤‘ë³µë˜ëŠ” ì½”ë“œë“¤ì€ ëª¨ë“ˆí™”, í´ë” êµ¬ì¡°ë¥¼ ë§ì¶°ì„œ ì½”ë“œ ë¦¬íŒ©í† ë§ì„ í•´ì¤˜. ì˜ˆë¥¼ë“¤ì–´, í´ë”/íŒŒì¼.í™•ì¥ì ì½”ë“œ, ë‹¤ìŒ í´ë”/íŒŒì¼.í™•ì¥ì ì½”ë“œ ì´ëŸ°ì‹ìœ¼ë¡œ. ê·¸ë¦¬ê³  ì „ì²´ì ì¸ í”„ë¡œì íŠ¸ ë£¨íŠ¸ í´ë”ë„ ë³´ì—¬ì¤˜.]
`;

    // ìµœì¢… í†µí•©ëœ ì¿¼ë¦¬ ìƒì„±
    const USER_QUERY = `
${USER_PROMPT_HEADER}

--- ì „ì²´ í”„ë¡œì íŠ¸ ì½”ë“œ ì‹œì‘: ì´ ${processedFiles.length}ê°œ íŒŒì¼ ---

${combinedContent}

--- ì „ì²´ í”„ë¡œì íŠ¸ ì½”ë“œ ë ---
`;
    // ----------------------------------------------------------------------

    try {
        // ğŸš¨ ìˆ˜ì •: Ollama 'generate' APIëŠ” promptì™€ system í•„ë“œë¥¼ ì§ì ‘ ì§€ì›í•©ë‹ˆë‹¤.
        const payload = {
            model: MODEL_NAME,
            prompt: USER_QUERY, // ì‚¬ìš©ì ìš”ì²­ ë° ì½”ë“œ ë‚´ìš©
            system: SYSTEM_PROMPT, // ì‹œìŠ¤í…œ ì§€ì¹¨ (LLM í˜ë¥´ì†Œë‚˜ ì„¤ì •)
            stream: false,
            options: {
                temperature: 0.2, // ì½”ë“œ ë¦¬íŒ©í† ë§ ë° ì°½ì˜ì  ì œì•ˆì„ ìœ„í•´ ì˜¨ë„ë¥¼ ì•½ê°„ ë†’ì„
            },
        };

        console.log(`\n--- Ollama API í˜¸ì¶œ ì‹œì‘ ---`);
        console.log(`ëª¨ë¸: ${MODEL_NAME}`);
        console.log(`ë¶„ì„ íŒŒì¼: ${processedFiles.join(", ")}`);
        console.log(`ìš”ì²­ í¬ê¸°: ${USER_QUERY.length} bytes`);
        console.log(
            `\në¶„ì„ ì‘ì—…ì€ LLMì˜ ëª¨ë¸ í¬ê¸°ë¡œ ì¸í•´ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (5ì´ˆ ~ 30ì´ˆ ì´ìƒ). ì ì‹œ ê¸°ë‹¤ë ¤ ì£¼ì‹­ì‹œì˜¤...\n`
        );

        // Node.jsì˜ ë‚´ì¥ fetch ì‚¬ìš©
        const response = await fetch(OLLAMA_URL, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(payload),
        });

        if (!response.ok) {
            // ìƒì„¸ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í¬í•¨
            const errorBody = await response.text();
            throw new Error(
                `Ollama HTTP Error: ${response.status} ${response.statusText}. ìƒì„¸: ${errorBody}`
            );
        }

        const data = await response.json();

        console.log(`--- Ollama ë¶„ì„ ê²°ê³¼ ---`);
        // ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•˜ì—¬ ì¶œë ¥
        console.log(
            data.response ? data.response.trim() : "LLM ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        );
        console.log(`\n--- Ollama API í˜¸ì¶œ ì¢…ë£Œ ---`);
    } catch (error) {
        console.error(`\nğŸš¨ Ollama API í˜¸ì¶œ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ:`);
        console.error(
            `Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€, ëª¨ë¸(${MODEL_NAME})ì´ ë¡œì»¬ì— ë‹¤ìš´ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤.`
        );
        console.error(`ìƒì„¸ ì˜¤ë¥˜:`, error.message);
    }
}

// ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
// ìµœìƒìœ„ awaitì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
callOllama();
